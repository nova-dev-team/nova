##############################################################
#
#			worker design
#
##############################################################

worker assumes that all operations are correct and could be completed. that means, worker will not check if params are valid.

api draft:

==============================================================

start vm
GET&POST /vmachines/start
async call, immediately return. it should be called by master_helper in a background queue. and when worker received the call, it calls worker_helper, who forks a new process, and gets the job done.
params:
  name=name of the vm
  hypervisor=which hypervisor do we use? "kvm", "xen", "vbox"
  cpu_count=number of CPUs
  mem_size=memory size in MB
  sys_arch=system architecture, "x86_64", "i386"
  hda_image=URI of hda image
  hda_save_to=where will the hda image be saved, when vm halts (optional) (not including "destroy")
  hdb_image=URI of hdb image (optional)
  hdb_save_to=where will the hdb image be saved, when vm halts (optional) (not including "destroy")
  cd_image=URI of cdrom image (optional)
  run_agent=need to run agent (default is true, if soft_list given)
NOTE:
if "xxx_save_to" is "", the image will be discarded when vm halts (not including "destroy")
return:
on success:
  {success:true, message:"...", uuid:"..."}
on failure (not enough resource, etc.):
  {success:false, message:"..."}

==============================================================

show status of the vm
GET&POST /vmachines/status
possible statuses:
  starting: healthy, waiting for resource (generally hda image, downloading)
  failed to start: unhealthy, something goes wrong, and the vm is dead. master_helper will notice this, and report failure to end user
  installing: healthy, the vm is installing softwares. end user (except admins/root) could not VNC it
  running: healthy, the vm is running, and end user could VNC it
  suspended: healthy, the vm is suspended
  saving: healthy, the vm is shut down, and being saved. 3 times re-try
  failed to save: unhealthy, the vm is shut down, but failed to be saved. the local vm image will not be deleted in this case, they will be moved to a "failed_to_save" folder
params:
  uuid=vm uuid
  name=name of the vm
NOTE:
given any one of uuid/name. if both given, uuid is used
return:
on success:
  {success:true, message:"...", uuid:"...", name:"...", status:"...", vnc:"..."}

==============================================================

modify vm settings
GET&POST /vmachines/modify
params:
  hda_save_to=where will the hda image be saved, when vm halts (not including "destroy")
  hdb_save_to=where will the hdb image be saved, when vm halts (not including "destroy")
  cd_image=URI of cdrom image (only usable when "installing" is done) (implement if not hard)
NOTE:
if "xxx_save_to" is "", the image will be discarded when vm halts (not including "destroy")
if cd_image is "", the cd image will be detached

==============================================================

destroy vm
GET&POST /vmachines/destroy
when a vm is destoyed, its vm image will not be saved
params:
  uuid=vm uuid
  name=name of the vm
NOTE:
given any one of uuid/name. if both given, uuid is used

==============================================================

suspend vm
GET&POST /vmachines/suspend
params:
  uuid=vm uuid
  name=name of the vm
NOTE:
given any one of uuid/name. if both given, uuid is used

==============================================================

resume vm
GET&POST /vmachines/resume
params:
  uuid=vm uuid
  name=name of the vm
NOTE:
given any one of uuid/name. if both given, uuid is used


==============================================================

webui
GET /webui
GET /
show html page of worker interface



##############################################################
#
#			master design
#
##############################################################

master has 2 daemons, called "status_pusher" & "status_poller". When vm are created,
the settings will be saved into master's DB, and then "pusher" is triggerred.
The pusher will check master DB, and tries to push vm status to workers. If master DB
says a vm should be up and running, while they are actually not running, it is pusher's
job to start the vm, make the "real" status of the vm to be equal to master's "assumed"
status of the vm.

Poller, on the other hand, is not triggerred frequently. It is automatically called
every a few minutes, checks workers for their status. It is designed for fault-detecting.


vm status
=========
The VMs has those statuses:

* pending: the "start" action is in queue, to be carried out by "pusher" (assumed: "starting", real: nil)
* preparing: the "start" action is carried out by pusher, worker is preparing for it (assumed: "preparing", real: "preparing")
* installing: the agent is installing the VM (assumed: "installing", real: "running")
* running: the agent has finished installing the VM
* paused: the VM is paused
* destroying:

"pause" & "destroy" action will be carried out immediately. They are blocking call.


